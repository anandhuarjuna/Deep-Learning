{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmwJQjvzRKleBKDJUuJshd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anandhuarjuna/Deep-Learning/blob/main/Deep_Learning_Framingham_data_set.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sc-i209rV6Ls"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('/content/framingham.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "YasgwfdvW6P8",
        "outputId": "16cdc97a-7366-4334-e392-1f2464442473"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      male  age  education  currentSmoker  cigsPerDay  BPMeds  \\\n",
              "0        1   39        4.0              0         0.0     0.0   \n",
              "1        0   46        2.0              0         0.0     0.0   \n",
              "2        1   48        1.0              1        20.0     0.0   \n",
              "3        0   61        3.0              1        30.0     0.0   \n",
              "4        0   46        3.0              1        23.0     0.0   \n",
              "...    ...  ...        ...            ...         ...     ...   \n",
              "4235     0   48        2.0              1        20.0     NaN   \n",
              "4236     0   44        1.0              1        15.0     0.0   \n",
              "4237     0   52        2.0              0         0.0     0.0   \n",
              "4238     1   40        3.0              0         0.0     0.0   \n",
              "4239     0   39        3.0              1        30.0     0.0   \n",
              "\n",
              "      prevalentStroke  prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  \\\n",
              "0                   0             0         0    195.0  106.0   70.0  26.97   \n",
              "1                   0             0         0    250.0  121.0   81.0  28.73   \n",
              "2                   0             0         0    245.0  127.5   80.0  25.34   \n",
              "3                   0             1         0    225.0  150.0   95.0  28.58   \n",
              "4                   0             0         0    285.0  130.0   84.0  23.10   \n",
              "...               ...           ...       ...      ...    ...    ...    ...   \n",
              "4235                0             0         0    248.0  131.0   72.0  22.00   \n",
              "4236                0             0         0    210.0  126.5   87.0  19.16   \n",
              "4237                0             0         0    269.0  133.5   83.0  21.47   \n",
              "4238                0             1         0    185.0  141.0   98.0  25.60   \n",
              "4239                0             0         0    196.0  133.0   86.0  20.91   \n",
              "\n",
              "      heartRate  glucose  TenYearCHD  \n",
              "0          80.0     77.0           0  \n",
              "1          95.0     76.0           0  \n",
              "2          75.0     70.0           0  \n",
              "3          65.0    103.0           1  \n",
              "4          85.0     85.0           0  \n",
              "...         ...      ...         ...  \n",
              "4235       84.0     86.0           0  \n",
              "4236       86.0      NaN           0  \n",
              "4237       80.0    107.0           0  \n",
              "4238       67.0     72.0           0  \n",
              "4239       85.0     80.0           0  \n",
              "\n",
              "[4240 rows x 16 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e699c45-676c-423b-a942-349546c1533d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>male</th>\n",
              "      <th>age</th>\n",
              "      <th>education</th>\n",
              "      <th>currentSmoker</th>\n",
              "      <th>cigsPerDay</th>\n",
              "      <th>BPMeds</th>\n",
              "      <th>prevalentStroke</th>\n",
              "      <th>prevalentHyp</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>totChol</th>\n",
              "      <th>sysBP</th>\n",
              "      <th>diaBP</th>\n",
              "      <th>BMI</th>\n",
              "      <th>heartRate</th>\n",
              "      <th>glucose</th>\n",
              "      <th>TenYearCHD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>26.97</td>\n",
              "      <td>80.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>46</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>28.73</td>\n",
              "      <td>95.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>48</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>245.0</td>\n",
              "      <td>127.5</td>\n",
              "      <td>80.0</td>\n",
              "      <td>25.34</td>\n",
              "      <td>75.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>225.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>28.58</td>\n",
              "      <td>65.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>46</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>285.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>23.10</td>\n",
              "      <td>85.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4235</th>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>20.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>248.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>22.00</td>\n",
              "      <td>84.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4236</th>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>210.0</td>\n",
              "      <td>126.5</td>\n",
              "      <td>87.0</td>\n",
              "      <td>19.16</td>\n",
              "      <td>86.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4237</th>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>269.0</td>\n",
              "      <td>133.5</td>\n",
              "      <td>83.0</td>\n",
              "      <td>21.47</td>\n",
              "      <td>80.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4238</th>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>185.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>25.60</td>\n",
              "      <td>67.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4239</th>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>196.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>20.91</td>\n",
              "      <td>85.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4240 rows × 16 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e699c45-676c-423b-a942-349546c1533d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4e699c45-676c-423b-a942-349546c1533d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4e699c45-676c-423b-a942-349546c1533d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTtbHb-CXkY-",
        "outputId": "f76bd530-1a89-4a1d-c0b5-5bdcd26ac115"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "male                 0\n",
              "age                  0\n",
              "education          105\n",
              "currentSmoker        0\n",
              "cigsPerDay          29\n",
              "BPMeds              53\n",
              "prevalentStroke      0\n",
              "prevalentHyp         0\n",
              "diabetes             0\n",
              "totChol             50\n",
              "sysBP                0\n",
              "diaBP                0\n",
              "BMI                 19\n",
              "heartRate            1\n",
              "glucose            388\n",
              "TenYearCHD           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['education'],axis=1,inplace=True)\n"
      ],
      "metadata": {
        "id": "apdbd76AXpcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['cigsPerDay']=df['cigsPerDay'].fillna(df['cigsPerDay'].mode()[0])\n",
        "df['BPMeds']=df['BPMeds'].fillna(df['BPMeds'].mode()[0])\n",
        "df['totChol']=df['totChol'].fillna(df['totChol'].mode()[0])\n",
        "df['BMI']=df['BMI'].fillna(df['BMI'].mean())\n",
        "df['heartRate']=df['heartRate'].fillna(df['heartRate'].mode()[0])\n",
        "df['glucose']=df['glucose'].fillna(df['glucose'].mode()[0])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "u7G_bBvYYdhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()\n",
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1aWXrM9ZziR",
        "outputId": "17f00ee7-315c-4170-b76a-6efc87c83462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "male                 int64\n",
              "age                  int64\n",
              "currentSmoker        int64\n",
              "cigsPerDay         float64\n",
              "BPMeds             float64\n",
              "prevalentStroke      int64\n",
              "prevalentHyp         int64\n",
              "diabetes             int64\n",
              "totChol            float64\n",
              "sysBP              float64\n",
              "diaBP              float64\n",
              "BMI                float64\n",
              "heartRate          float64\n",
              "glucose            float64\n",
              "TenYearCHD           int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.iloc[:,:-1]\n",
        "y=df.iloc[:,-1]\n"
      ],
      "metadata": {
        "id": "DezT2a40Z5uV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc=StandardScaler()\n",
        "X_new=sc.fit_transform(X)"
      ],
      "metadata": {
        "id": "YLpWCU6Qa0V5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X_new,y,test_size=.3,random_state=50)"
      ],
      "metadata": {
        "id": "V_p2YwgYbas8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "ann=Sequential()\n",
        "ann.add(keras.layers.Dense(20,activation='relu'))\n",
        "ann.add(keras.layers.Dense(22,activation='relu'))\n",
        "ann.add(keras.layers.Dense(24,activation='relu'))\n",
        "ann.add(keras.layers.Dense(1,activation='sigmoid'))\n"
      ],
      "metadata": {
        "id": "1oYRSXaFb0YA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "xjsiUBW3dEIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.fit(X_train,y_train,epochs=150,batch_size=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moL9gv8YdSV0",
        "outputId": "d6854814-125c-443d-dbed-b7cbfa709fc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.4267 - accuracy: 0.8484\n",
            "Epoch 2/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.3802 - accuracy: 0.8555\n",
            "Epoch 3/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.3736 - accuracy: 0.8571\n",
            "Epoch 4/150\n",
            "594/594 [==============================] - 3s 5ms/step - loss: 0.3662 - accuracy: 0.8582\n",
            "Epoch 5/150\n",
            "594/594 [==============================] - 2s 4ms/step - loss: 0.3615 - accuracy: 0.8598\n",
            "Epoch 6/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.3575 - accuracy: 0.8629\n",
            "Epoch 7/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.3551 - accuracy: 0.8632\n",
            "Epoch 8/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.3536 - accuracy: 0.8652\n",
            "Epoch 9/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.3490 - accuracy: 0.8649\n",
            "Epoch 10/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.3465 - accuracy: 0.8656\n",
            "Epoch 11/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.3442 - accuracy: 0.8683\n",
            "Epoch 12/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.3426 - accuracy: 0.8679\n",
            "Epoch 13/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.3394 - accuracy: 0.8689\n",
            "Epoch 14/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.3377 - accuracy: 0.8676\n",
            "Epoch 15/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.3325 - accuracy: 0.8703\n",
            "Epoch 16/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.3307 - accuracy: 0.8726\n",
            "Epoch 17/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.3286 - accuracy: 0.8730\n",
            "Epoch 18/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.3244 - accuracy: 0.8720\n",
            "Epoch 19/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.3212 - accuracy: 0.8733\n",
            "Epoch 20/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.3206 - accuracy: 0.8757\n",
            "Epoch 21/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.3173 - accuracy: 0.8733\n",
            "Epoch 22/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.3131 - accuracy: 0.8794\n",
            "Epoch 23/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.3131 - accuracy: 0.8767\n",
            "Epoch 24/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.3078 - accuracy: 0.8787\n",
            "Epoch 25/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.3041 - accuracy: 0.8807\n",
            "Epoch 26/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.3009 - accuracy: 0.8814\n",
            "Epoch 27/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2997 - accuracy: 0.8814\n",
            "Epoch 28/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2938 - accuracy: 0.8885\n",
            "Epoch 29/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2935 - accuracy: 0.8821\n",
            "Epoch 30/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2922 - accuracy: 0.8871\n",
            "Epoch 31/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2893 - accuracy: 0.8854\n",
            "Epoch 32/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2877 - accuracy: 0.8878\n",
            "Epoch 33/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2824 - accuracy: 0.8898\n",
            "Epoch 34/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2812 - accuracy: 0.8888\n",
            "Epoch 35/150\n",
            "594/594 [==============================] - 2s 4ms/step - loss: 0.2767 - accuracy: 0.8922\n",
            "Epoch 36/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2769 - accuracy: 0.8925\n",
            "Epoch 37/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2740 - accuracy: 0.8952\n",
            "Epoch 38/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2711 - accuracy: 0.8959\n",
            "Epoch 39/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2703 - accuracy: 0.8939\n",
            "Epoch 40/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2657 - accuracy: 0.8976\n",
            "Epoch 41/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2667 - accuracy: 0.8945\n",
            "Epoch 42/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2644 - accuracy: 0.8986\n",
            "Epoch 43/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2625 - accuracy: 0.8956\n",
            "Epoch 44/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2574 - accuracy: 0.8999\n",
            "Epoch 45/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2584 - accuracy: 0.9009\n",
            "Epoch 46/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2571 - accuracy: 0.9030\n",
            "Epoch 47/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2533 - accuracy: 0.9030\n",
            "Epoch 48/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2501 - accuracy: 0.9036\n",
            "Epoch 49/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2477 - accuracy: 0.9033\n",
            "Epoch 50/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2478 - accuracy: 0.9030\n",
            "Epoch 51/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2446 - accuracy: 0.9057\n",
            "Epoch 52/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2408 - accuracy: 0.9067\n",
            "Epoch 53/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2404 - accuracy: 0.9050\n",
            "Epoch 54/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2397 - accuracy: 0.9080\n",
            "Epoch 55/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2374 - accuracy: 0.9111\n",
            "Epoch 56/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2333 - accuracy: 0.9151\n",
            "Epoch 57/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2341 - accuracy: 0.9057\n",
            "Epoch 58/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2314 - accuracy: 0.9131\n",
            "Epoch 59/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2247 - accuracy: 0.9141\n",
            "Epoch 60/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2273 - accuracy: 0.9141\n",
            "Epoch 61/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2240 - accuracy: 0.9144\n",
            "Epoch 62/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2248 - accuracy: 0.9144\n",
            "Epoch 63/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2233 - accuracy: 0.9124\n",
            "Epoch 64/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2212 - accuracy: 0.9168\n",
            "Epoch 65/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2199 - accuracy: 0.9175\n",
            "Epoch 66/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2177 - accuracy: 0.9137\n",
            "Epoch 67/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2157 - accuracy: 0.9205\n",
            "Epoch 68/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2134 - accuracy: 0.9178\n",
            "Epoch 69/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2141 - accuracy: 0.9181\n",
            "Epoch 70/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2110 - accuracy: 0.9195\n",
            "Epoch 71/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2088 - accuracy: 0.9208\n",
            "Epoch 72/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2090 - accuracy: 0.9158\n",
            "Epoch 73/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2043 - accuracy: 0.9255\n",
            "Epoch 74/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2028 - accuracy: 0.9225\n",
            "Epoch 75/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2015 - accuracy: 0.9228\n",
            "Epoch 76/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1989 - accuracy: 0.9272\n",
            "Epoch 77/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.2017 - accuracy: 0.9252\n",
            "Epoch 78/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1983 - accuracy: 0.9232\n",
            "Epoch 79/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1951 - accuracy: 0.9282\n",
            "Epoch 80/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1929 - accuracy: 0.9232\n",
            "Epoch 81/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1939 - accuracy: 0.9239\n",
            "Epoch 82/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1856 - accuracy: 0.9306\n",
            "Epoch 83/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1902 - accuracy: 0.9316\n",
            "Epoch 84/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1874 - accuracy: 0.9272\n",
            "Epoch 85/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1840 - accuracy: 0.9336\n",
            "Epoch 86/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1854 - accuracy: 0.9333\n",
            "Epoch 87/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1830 - accuracy: 0.9286\n",
            "Epoch 88/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1841 - accuracy: 0.9303\n",
            "Epoch 89/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1793 - accuracy: 0.9313\n",
            "Epoch 90/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1799 - accuracy: 0.9296\n",
            "Epoch 91/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1772 - accuracy: 0.9323\n",
            "Epoch 92/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1746 - accuracy: 0.9336\n",
            "Epoch 93/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1744 - accuracy: 0.9367\n",
            "Epoch 94/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1767 - accuracy: 0.9343\n",
            "Epoch 95/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1713 - accuracy: 0.9350\n",
            "Epoch 96/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1707 - accuracy: 0.9367\n",
            "Epoch 97/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1680 - accuracy: 0.9363\n",
            "Epoch 98/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1680 - accuracy: 0.9367\n",
            "Epoch 99/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1682 - accuracy: 0.9383\n",
            "Epoch 100/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1639 - accuracy: 0.9380\n",
            "Epoch 101/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1651 - accuracy: 0.9390\n",
            "Epoch 102/150\n",
            "594/594 [==============================] - 2s 4ms/step - loss: 0.1636 - accuracy: 0.9377\n",
            "Epoch 103/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1575 - accuracy: 0.9410\n",
            "Epoch 104/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1631 - accuracy: 0.9407\n",
            "Epoch 105/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1596 - accuracy: 0.9377\n",
            "Epoch 106/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1580 - accuracy: 0.9427\n",
            "Epoch 107/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1624 - accuracy: 0.9383\n",
            "Epoch 108/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1529 - accuracy: 0.9414\n",
            "Epoch 109/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1562 - accuracy: 0.9404\n",
            "Epoch 110/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1532 - accuracy: 0.9431\n",
            "Epoch 111/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1513 - accuracy: 0.9417\n",
            "Epoch 112/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1544 - accuracy: 0.9420\n",
            "Epoch 113/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1511 - accuracy: 0.9404\n",
            "Epoch 114/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1474 - accuracy: 0.9458\n",
            "Epoch 115/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1455 - accuracy: 0.9447\n",
            "Epoch 116/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1443 - accuracy: 0.9427\n",
            "Epoch 117/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1523 - accuracy: 0.9407\n",
            "Epoch 118/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1420 - accuracy: 0.9461\n",
            "Epoch 119/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1461 - accuracy: 0.9485\n",
            "Epoch 120/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1457 - accuracy: 0.9478\n",
            "Epoch 121/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1421 - accuracy: 0.9461\n",
            "Epoch 122/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1417 - accuracy: 0.9454\n",
            "Epoch 123/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1391 - accuracy: 0.9464\n",
            "Epoch 124/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1358 - accuracy: 0.9488\n",
            "Epoch 125/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1403 - accuracy: 0.9458\n",
            "Epoch 126/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1394 - accuracy: 0.9522\n",
            "Epoch 127/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1351 - accuracy: 0.9511\n",
            "Epoch 128/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1328 - accuracy: 0.9511\n",
            "Epoch 129/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1365 - accuracy: 0.9538\n",
            "Epoch 130/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1402 - accuracy: 0.9491\n",
            "Epoch 131/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1309 - accuracy: 0.9528\n",
            "Epoch 132/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1363 - accuracy: 0.9485\n",
            "Epoch 133/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1291 - accuracy: 0.9508\n",
            "Epoch 134/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1357 - accuracy: 0.9485\n",
            "Epoch 135/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1289 - accuracy: 0.9549\n",
            "Epoch 136/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1344 - accuracy: 0.9478\n",
            "Epoch 137/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1275 - accuracy: 0.9545\n",
            "Epoch 138/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1248 - accuracy: 0.9535\n",
            "Epoch 139/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1235 - accuracy: 0.9582\n",
            "Epoch 140/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1242 - accuracy: 0.9552\n",
            "Epoch 141/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1288 - accuracy: 0.9528\n",
            "Epoch 142/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1250 - accuracy: 0.9535\n",
            "Epoch 143/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1187 - accuracy: 0.9589\n",
            "Epoch 144/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1230 - accuracy: 0.9508\n",
            "Epoch 145/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1345 - accuracy: 0.9535\n",
            "Epoch 146/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1306 - accuracy: 0.9501\n",
            "Epoch 147/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1151 - accuracy: 0.9639\n",
            "Epoch 148/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1142 - accuracy: 0.9579\n",
            "Epoch 149/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1120 - accuracy: 0.9619\n",
            "Epoch 150/150\n",
            "594/594 [==============================] - 2s 3ms/step - loss: 0.1225 - accuracy: 0.9528\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7febe20adcd0>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=ann.predict(X_test)\n",
        "y_pred=(y_pred>.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hO5mQxVewQr",
        "outputId": "b704e037-980f-4164-ae87-f9f54d43d3c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40/40 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report,ConfusionMatrixDisplay\n",
        "print(ConfusionMatrixDisplay.from_predictions(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "d7FQsngLe3p4",
        "outputId": "1d8f90db-13c2-496a-85c8-a79d32154b4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay object at 0x7fec3054ed60>\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87      1069\n",
            "           1       0.27      0.24      0.26       203\n",
            "\n",
            "    accuracy                           0.78      1272\n",
            "   macro avg       0.57      0.56      0.56      1272\n",
            "weighted avg       0.77      0.78      0.77      1272\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nee_bagHWgbR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}